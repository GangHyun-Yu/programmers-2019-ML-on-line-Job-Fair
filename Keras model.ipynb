{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -U git+https://github.com/qubvel/efficientnet","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\n\nimport tensorflow as tf\nimport keras\n\nfrom keras.preprocessing import image\n\nfrom keras.layers import Conv2D,Dropout,Dense,Flatten\nfrom keras.models import Sequential\n\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.models import Sequential, Model\nfrom keras.layers import Activation, Convolution2D, MaxPooling2D, BatchNormalization, Flatten, Dense, Dropout, Conv2D,MaxPool2D, ZeroPadding2D\n\nimport efficientnet.keras as efn\n\nprint(tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"INPUT_PATH = '/kaggle/input'\nIMAGE_DIR = os.path.join(INPUT_PATH, 'faces_images/faces_images')\nTRAIN_CSV_PATH = os.path.join(INPUT_PATH, 'train_vision.csv')\nTEST_CSV_PATH = os.path.join(INPUT_PATH, 'test_vision.csv')\n\nos.listdir(INPUT_PATH)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_csv = pd.read_csv(TRAIN_CSV_PATH)\ntest_csv = pd.read_csv(TEST_CSV_PATH)\n\ntrain_csv.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_csv['label'].hist()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def load_image_array(image_path):\n    img = image.load_img(image_path, target_size=(128, 128))\n    image_array = image.img_to_array(img)\n    \n    return image_array\n    \ndef load_image_data(filenames):\n    image_data = [load_image_array(os.path.join(IMAGE_DIR, filename)) for filename in filenames]\n    \n    return np.array(image_data).astype(float)/255.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = load_image_data(train_csv['filename'].values)\ny_train = pd.get_dummies(train_csv['label'].astype(str))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train[:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Classify Y Data for Triple Model\n\n- glasses\n    - 0: [1, 3, 4, 6]\n    - 1: [2, 5]\n    \n    \n- age (children)\n    - 0: [1, 2, 4, 5]\n    - 1: [3, 6]\n    \n    \n- gender (femail)\n    - 0: [1, 2, 3]\n    - 1: [4, 5, 6]\n    \n    "},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in ['glasses', 'children', 'femail']:\n    y_train[column] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.loc[(y_train['2']==1) | (y_train['5']==1), 'glasses'] = 1\ny_train.loc[(y_train['3']==1) | (y_train['6']==1), 'children'] = 1\ny_train.loc[(y_train['4']==1) | (y_train['5']==1) | (y_train['6']==1), 'femail'] = 1\n\ny_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_glasses = y_train['glasses']\ny_train_age = y_train['children']\ny_train_gender = y_train['femail']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Defining a Model"},{"metadata":{},"cell_type":"markdown","source":"- custom Keras model\n    - https://www.kaggle.com/karanjakhar/facial-keypoint-detection/notebook\n\n\n- Efficientnet\n    - https://github.com/titu1994/keras-efficientnets\n    - https://www.dlology.com/blog/transfer-learning-with-efficientnet/\n    - https://www.kaggle.com/mobassir/keras-efficientnetb2-for-classifying-cloud"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model(input_shape=(128,128,3)):\n    model = Sequential()\n\n    model.add(Convolution2D(32, (3,3), padding='same', use_bias=False, input_shape=input_shape))\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(BatchNormalization())\n    \n    model.add(Convolution2D(32, (3,3), padding='same', use_bias=False))\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(pool_size=(2, 2)))\n\n    model.add(Convolution2D(64, (3,3), padding='same', use_bias=False))\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(BatchNormalization())\n\n    model.add(Convolution2D(64, (3,3), padding='same', use_bias=False))\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(pool_size=(2, 2)))\n\n    model.add(Convolution2D(96, (3,3), padding='same', use_bias=False))\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(BatchNormalization())\n\n    model.add(Convolution2D(96, (3,3), padding='same', use_bias=False))\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(pool_size=(2,2)))\n\n    model.add(Convolution2D(128, (3,3),padding='same', use_bias=False))\n    # model.add(BatchNormalization())\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(BatchNormalization())\n\n    model.add(Convolution2D(128, (3,3),padding='same', use_bias=False))\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(pool_size=(2,2)))\n\n    model.add(Convolution2D(256, (3,3),padding='same',use_bias=False))\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(BatchNormalization())\n\n    model.add(Convolution2D(256, (3,3),padding='same',use_bias=False))\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(pool_size=(2,2)))\n\n    model.add(Convolution2D(512, (3,3), padding='same', use_bias=False))\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(BatchNormalization())\n    \n    model.add(Convolution2D(512, (3,3), padding='same', use_bias=False))\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(BatchNormalization())\n    \n    model.add(Flatten())\n    model.add(Dense(512, activation='relu'))\n    model.add(Dropout(0.1))\n    model.add(Dense(128, activation='relu'))\n    model.add(Dropout(0.1))\n    model.add(Dense(1, activation='sigmoid'))\n    \n    model.compile(optimizer='adam',\n                  loss='binary_crossentropy',\n                  metrics=['accuracy'])\n    \n    return model\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model_efficient(input_shape=(128,128,3)):\n    base_model = efn.EfficientNetB5(weights='imagenet', include_top=False, input_shape=input_shape)\n    base_model.trainable = False\n    \n    x = base_model.output\n    x = Flatten()(x)\n    x = Dense(1024, activation=\"relu\")(x)\n    x = Dropout(0.5)(x)\n    \n    #y_pred = Dense(6, activation=\"softmax\")(x)\n    y_pred = Dense(1, activation=\"sigmoid\")(x)\n    \n    #loss = 'categorical_crossentropy'\n    loss = 'binary_crossentropy'\n    \n    model = Model(input=base_model.input, output=y_pred)\n    \n    for base_layer in model.layers[:-3]:\n        base_layer.trainable = True\n        \n    model.compile(optimizer='adam',\n                  loss=loss,\n                  metrics=['accuracy'])\n    \n    \n    return model\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_glasses = get_model_efficient()\nmodel_age = get_model_efficient()\nmodel_gender = get_model_efficient()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train"},{"metadata":{"trusted":true},"cell_type":"code","source":"models = [model_glasses, model_age, model_gender]\ny_trains = [y_train_glasses, y_train_age, y_train_gender]\n\nfor i in range(3):\n    models[i].fit(X_train, y_trains[i], \n                  epochs=10, batch_size=32, validation_split=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_gender.fit(X_train, y_train_gender, \n                 epochs=10, batch_size=32, validation_split=0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Test for Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = load_image_data(test_csv['filename'].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_glasses = model_glasses.predict(X_test).reshape(-1)\npredict_age = model_age.predict(X_test).reshape(-1)\npredict_gender = model_gender.predict(X_test).reshape(-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = pd.DataFrame({'glass': list(predict_glasses), \n                       'children': list(predict_age), \n                       'femail': list(predict_gender)})\ny_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred['predict'] = 0\n\ny_pred.loc[(y_pred['glass']<0.5)&(y_pred['children']<0.5)&(y_pred['femail']<0.5), 'predict'] = 1\ny_pred.loc[(y_pred['glass']>=0.5)&(y_pred['children']<0.5)&(y_pred['femail']<0.5), 'predict'] = 2\ny_pred.loc[(y_pred['glass']>=0.5)&(y_pred['children']>=0.5)&(y_pred['femail']<0.5), 'predict'] = 2\ny_pred.loc[(y_pred['glass']<0.5)&(y_pred['children']>=0.5)&(y_pred['femail']<0.5), 'predict'] = 3\n\ny_pred.loc[(y_pred['glass']<0.5)&(y_pred['children']<0.5)&(y_pred['femail']>=0.5), 'predict'] = 4\ny_pred.loc[(y_pred['glass']>=0.5)&(y_pred['children']<0.5)&(y_pred['femail']>=0.5), 'predict'] = 5\ny_pred.loc[(y_pred['glass']>=0.5)&(y_pred['children']>=0.5)&(y_pred['femail']>=0.5), 'predict'] = 5\ny_pred.loc[(y_pred['glass']<0.5)&(y_pred['children']>=0.5)&(y_pred['femail']>=0.5), 'predict'] = 6\n\ny_pred.head(50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit = pd.DataFrame({'prediction': y_pred['predict'].values})\nsubmit","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit.to_csv('submission_19.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n# Public Score History\n1. 83.25 (single model)\n2. 85.50\n3. 87.50 (triple model)\n4. 87.50\n5. 87.50\n6. 87.50\n7. 87.25 (threshold 0.4)\n8. 84.00\n9. 84.25\n10. 84.00\n11. 09.00\n12. 86.50\n13. 85.50 (single efficientnet B0)\n14. 89.25 (single efficientnet B7)\n15. 86.75 (triple efficientnet B0)\n16. 88.25\n17. 87.50\n18. 88.00\n19. 88.00 (triple efficientnet B5)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}